{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T19:38:00.959602Z",
     "start_time": "2024-12-08T19:38:00.612121Z"
    }
   },
   "outputs": [],
   "source": [
    "from metrics import *\n",
    "from bert import *\n",
    "from tf_idf import * \n",
    "from random_sample import *\n",
    "from w2v import *\n",
    "from ivec import *\n",
    "from vgg import *\n",
    "from resnet import *\n",
    "from incp import *\n",
    "from f_a import *\n",
    "from f_a_adv import *\n",
    "from mfcc import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is properly set up\n",
    "print(torch.cuda.get_device_name(0))  # Should print your GPU's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = pd.read_csv(\"dataset/id_information_mmsr.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for TF-IDF processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9cf10d0c9d485daae65741f103a508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing TF-IDF Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf_idf = pd.read_csv(\"dataset/id_lyrics_tf-idf_mmsr.tsv\", sep=\"\\t\")\n",
    "recs_tf_idf = all_tf_idf(infos, tf_idf, topK=10)\n",
    "np.savetxt(\"./predictions/recs_tf_idf_10.csv\", recs_tf_idf, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for BERT processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0372d1c56f414aa284bd0d9658310559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing BERT Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert = pd.read_csv(\"dataset/id_lyrics_bert_mmsr.tsv\", sep=\"\\t\")\n",
    "recs_bert = all_bert_recs(infos, bert, topK=10)\n",
    "np.savetxt(\"./predictions/recs_bert_10.csv\", recs_bert, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for Random Recommendations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2e53ede61c47b58fbb755f080fe12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Random Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recs_random = all_random_recs(infos, topK=10)\n",
    "np.savetxt(\"./predictions/recs_random_10.csv\", recs_random, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarity matrix for 5148 items.\n",
      "Using 12 cores for similarity matrix computation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6192614c4674582af9e73ba02138bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing Similarity Matrix:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 cores for item-item processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5d149fc39442089d0b6cc3ee92ac6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Item-Item Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recs_item_item = all_item_item_recs(infos, topK=10)\n",
    "np.savetxt(\"./predictions/recs_item_item_10.csv\", recs_item_item, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for Word2Vec recommendation processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07e59dbc4284e98bd9456c1dcec5634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Word2Vec Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word2vec = pd.read_csv(\"dataset/id_lyrics_word2vec_mmsr.tsv\", sep=\"\\t\")  # Word2Vec embeddings\n",
    "recs_word2vec = all_word2vec_recs(infos, word2vec, topK=10)\n",
    "np.savetxt(\"./predictions/recs_word2vec_10.csv\", recs_word2vec, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for iVector recommendation processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6138fcff4d3344ce9c46334fa172b451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing iVector Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ivec256 = pd.read_csv(\"dataset/id_ivec256_mmsr.tsv\", sep=\"\\t\")        # iVector (256 dimensions)\n",
    "ivec512 = pd.read_csv(\"dataset/id_ivec512_mmsr.tsv\", sep=\"\\t\")        # iVector (512 dimensions)\n",
    "ivec1024 = pd.read_csv(\"dataset/id_ivec1024_mmsr.tsv\", sep=\"\\t\")      # iVector (1024 dimensions)\n",
    "recs_ivec = all_ivec_recs(infos, ivec256, ivec512, ivec1024, topK=10)\n",
    "np.savetxt(\"./predictions/recs_ivec_10.csv\", recs_ivec, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for VGG19 recommendation processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75c1d4071be4d0bb7cfa44f987ef3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing VGG19 Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgg19 = pd.read_csv(\"dataset/id_vgg19_mmsr.tsv\", sep=\"\\t\")        # VGG19 features\n",
    "recs_vgg19 = all_vgg19_recs(infos, vgg19, topK=10)\n",
    "np.savetxt(\"./predictions/recs_vgg19_10.csv\", recs_vgg19, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for ResNet processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fad9f5c47aa4f54807d7a99c91cd9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ResNet Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet = pd.read_csv(\"dataset/id_resnet_mmsr.tsv\", sep=\"\\t\")\n",
    "recs_resnet = all_resnet_recs(infos, resnet, topK=10)\n",
    "np.savetxt(\"./predictions/recs_resnet_10.csv\", recs_resnet, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for Inception processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a053765fee4f91ae770d32f20055c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Inception Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inception = pd.read_csv(\"dataset/id_incp_mmsr.tsv\", sep=\"\\t\")\n",
    "recs_inception = all_inception_recs(infos, inception, topK=10)\n",
    "np.savetxt(\"./predictions/recs_incp_10.csv\", recs_inception, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for BERT processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6ab0b08b1a4147988a2352553cb398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing BERT Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert = pd.read_csv(\"dataset/id_lyrics_bert_mmsr.tsv\", sep=\"\\t\")\n",
    "recs_bert_adv = all_bert_recs_adv(infos, bert, topK=10, alpha=0.05)\n",
    "np.savetxt(\"./predictions/recs_bert_adv_10.csv\", recs_bert_adv, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for feature-aware recommendation generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acdc05aa36c4c12a193b439fc32e055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Feature-Aware Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genres = pd.read_csv(\"dataset/id_genres_mmsr.tsv\", sep=\"\\t\")\n",
    "tags = pd.read_csv(\"dataset/id_tags_dict.tsv\", sep=\"\\t\")\n",
    "ivec256 = pd.read_csv(\"dataset/id_ivec256_mmsr.tsv\", sep=\"\\t\")\n",
    "ivec512 = pd.read_csv(\"dataset/id_ivec512_mmsr.tsv\", sep=\"\\t\")\n",
    "ivec1024 = pd.read_csv(\"dataset/id_ivec1024_mmsr.tsv\", sep=\"\\t\")\n",
    "recs_fa = all_feature_aware_recs(\n",
    "    infos=infos,\n",
    "    genres=genres,\n",
    "    tags=tags,\n",
    "    ivec256=ivec256,\n",
    "    ivec512=ivec512,\n",
    "    ivec1024=ivec1024,\n",
    "    topK=10,        # Number of recommendations\n",
    "    alpha=1.0,      # Weight for genres\n",
    "    beta=1.0,       # Weight for tags\n",
    "    gamma=2.0       # Weight for ivec\n",
    ")\n",
    "np.savetxt(\"./predictions/recs_genre_tags_10.csv\", recs_fa, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 cores for feature-aware recommendation generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4955c60a764d4c8073adca7e93a963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Feature-Aware Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genres = pd.read_csv(\"dataset/id_genres_mmsr.tsv\", sep=\"\\t\")\n",
    "tags = pd.read_csv(\"dataset/id_tags_dict.tsv\", sep=\"\\t\")\n",
    "ivec256 = pd.read_csv(\"dataset/id_ivec256_mmsr.tsv\", sep=\"\\t\")\n",
    "ivec512 = pd.read_csv(\"dataset/id_ivec512_mmsr.tsv\", sep=\"\\t\")\n",
    "ivec1024 = pd.read_csv(\"dataset/id_ivec1024_mmsr.tsv\", sep=\"\\t\")\n",
    "recs_fa_adv = all_feature_aware_recs_novel(\n",
    "    infos=infos,\n",
    "    genres=genres,\n",
    "    tags=tags,\n",
    "    ivec256=ivec256,\n",
    "    ivec512=ivec512,\n",
    "    ivec1024=ivec1024,\n",
    "    topK=10,        # Number of recommendations\n",
    "    alpha=1.0,      # Weight for genres\n",
    "    beta=1.0,       # Weight for tags\n",
    "    gamma=2.0,       # Weight for ivec\n",
    "    novelty_weight=2.0 # Weight for novelty\n",
    ")\n",
    "np.savetxt(\"./predictions/recs_genre_tags_novel_10.csv\", recs_fa_adv, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f339b1ec5e3042e19cdd5ec6f44d77ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 cores for feature-aware recommendation generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407bdfdca7c2453bab7bb7cfa0d2e516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Feature-Aware Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 cores for feature-aware recommendation generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab880f72bac41f2ab8093309b51919b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Feature-Aware Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 cores for feature-aware recommendation generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b335bbb6a1f474d88e4280ae16f0be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Feature-Aware Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 cores for feature-aware recommendation generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60493072adc7436782635f60eaed07d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Feature-Aware Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 cores for feature-aware recommendation generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f0b3b636bc4e7ead656b2b066ea7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Feature-Aware Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 cores for feature-aware recommendation generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdf3b6a66c341da82a0e1af36ac9aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Feature-Aware Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 cores for feature-aware recommendation generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d229333396664825828a887238070c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Feature-Aware Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 cores for feature-aware recommendation generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889f2d40c85a400bacdff9f443dbf759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Feature-Aware Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 cores for feature-aware recommendation generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fa6e1818054e7785881b733f49d1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Feature-Aware Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 cores for feature-aware recommendation generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ac164085ac4cc897bb6813e66e53fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Feature-Aware Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genres = pd.read_csv(\"dataset/id_genres_mmsr.tsv\", sep=\"\\t\")\n",
    "tags = pd.read_csv(\"dataset/id_tags_dict.tsv\", sep=\"\\t\")\n",
    "ivec256 = pd.read_csv(\"dataset/id_ivec256_mmsr.tsv\", sep=\"\\t\")\n",
    "ivec512 = pd.read_csv(\"dataset/id_ivec512_mmsr.tsv\", sep=\"\\t\")\n",
    "ivec1024 = pd.read_csv(\"dataset/id_ivec1024_mmsr.tsv\", sep=\"\\t\")\n",
    "weight_combinations = [\n",
    "    (1.0, 1.0, 1.0),\n",
    "    (1.0, 1.0, 2.0),\n",
    "    (1.0, 0.5, 1.5),\n",
    "    (0.5, 1.5, 1.0),\n",
    "    (1.5, 0.5, 1.0),\n",
    "    (2.0, 1.0, 0.5),\n",
    "    (0.5, 1.0, 2.0),\n",
    "    (1.0, 2.0, 1.0),\n",
    "    (1.5, 2.0, 0.8),\n",
    "    (0.8, 1.2, 1.5),\n",
    "]\n",
    "\n",
    "for idx, (alpha, beta, gamma) in enumerate(tqdm(weight_combinations)):\n",
    "    recs_fa = all_feature_aware_recs(\n",
    "        infos=infos,\n",
    "        genres=genres,\n",
    "        tags=tags,\n",
    "        ivec256=ivec256,\n",
    "        ivec512=ivec512,\n",
    "        ivec1024=ivec1024,\n",
    "        topK=10,\n",
    "        alpha=alpha,\n",
    "        beta=beta,\n",
    "        gamma=gamma\n",
    "    )\n",
    "    np.savetxt(f\"./predictions/recs_genre_tags_weights_{idx}.csv\", recs_fa, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for MFCC processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931520df8c1d40a6a6898817b1e109c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing BERT Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mfcc = pd.read_csv(\"dataset/id_mfcc_stats_mmsr.tsv\", sep=\"\\t\")\n",
    "recs_mfcc = all_mfcc_recs(infos, mfcc, topK=10)\n",
    "np.savetxt(\"./predictions/recs_mfcc_stats_10.csv\", recs_mfcc, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for MFCC processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110bb57a835a4522b011263a234efa6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing BERT Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mfcc = pd.read_csv(\"dataset/id_mfcc_bow_mmsr.tsv\", sep=\"\\t\")\n",
    "recs_mfcc = all_mfcc_recs(infos, mfcc, topK=10)\n",
    "np.savetxt(\"./predictions/recs_mfcc_bow_10.csv\", recs_mfcc, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores for combined visual processing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2710929e1efb4bf0afef68c22d398c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Combined Visual Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m resnet \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/id_resnet_mmsr.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m inception \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/id_incp_mmsr.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m recs_combined \u001b[38;5;241m=\u001b[39m all_combined_visual_recs(infos, vgg, resnet, inception, topK\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./predictions/recs_combined_10.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, recs_combined, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\pythonProject\\MSR\\final\\combi.py:76\u001b[0m, in \u001b[0;36mall_combined_visual_recs\u001b[1;34m(infos, vgg, resnet, inception, topK)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m row\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm_joblib(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Combined Visual Recommendations\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(infos)):\n\u001b[1;32m---> 76\u001b[0m     recs \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(delayed(process_song)(song) \u001b[38;5;28;01mfor\u001b[39;00m _, song \u001b[38;5;129;01min\u001b[39;00m infos\u001b[38;5;241m.\u001b[39miterrows())\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(recs)\n",
      "File \u001b[1;32mD:\\conda_envs\\condaenv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mD:\\conda_envs\\condaenv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\conda_envs\\condaenv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg = pd.read_csv(\"dataset/id_vgg19_mmsr.tsv\", sep=\"\\t\")\n",
    "resnet = pd.read_csv(\"dataset/id_resnet_mmsr.tsv\", sep=\"\\t\")\n",
    "inception = pd.read_csv(\"dataset/id_incp_mmsr.tsv\", sep=\"\\t\")\n",
    "\n",
    "recs_combined = all_combined_visual_recs(infos, vgg, resnet, inception, topK=10)\n",
    "np.savetxt(\"./predictions/recs_combined_10.csv\", recs_combined, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 50.0934\n",
      "Epoch 2 Loss: 20.6406\n",
      "Epoch 3 Loss: 16.6384\n",
      "Epoch 4 Loss: 14.7414\n",
      "Epoch 5 Loss: 12.9402\n",
      "Epoch 6 Loss: 12.7494\n",
      "Epoch 7 Loss: 12.2106\n",
      "Epoch 8 Loss: 11.7453\n",
      "Epoch 9 Loss: 11.9937\n",
      "Epoch 10 Loss: 11.5846\n",
      "Epoch 11 Loss: 11.2977\n",
      "Epoch 12 Loss: 11.2253\n",
      "Epoch 13 Loss: 11.0308\n",
      "Epoch 14 Loss: 10.5052\n",
      "Epoch 15 Loss: 10.7580\n",
      "Epoch 16 Loss: 10.6048\n",
      "Epoch 17 Loss: 10.4701\n",
      "Epoch 18 Loss: 10.1134\n",
      "Epoch 19 Loss: 10.1738\n",
      "Epoch 20 Loss: 10.0687\n",
      "Epoch 21 Loss: 9.8841\n",
      "Epoch 22 Loss: 9.7731\n",
      "Epoch 23 Loss: 10.0034\n",
      "Epoch 24 Loss: 9.7913\n",
      "Epoch 25 Loss: 9.3920\n",
      "Epoch 26 Loss: 9.0427\n",
      "Epoch 27 Loss: 9.1448\n",
      "Epoch 28 Loss: 8.8439\n",
      "Epoch 29 Loss: 9.0697\n",
      "Epoch 30 Loss: 8.6243\n",
      "Epoch 31 Loss: 8.5269\n",
      "Epoch 32 Loss: 8.6410\n",
      "Epoch 33 Loss: 8.6179\n",
      "Epoch 34 Loss: 8.1824\n",
      "Epoch 35 Loss: 7.7668\n",
      "Epoch 36 Loss: 7.9358\n",
      "Epoch 37 Loss: 7.8217\n",
      "Epoch 38 Loss: 7.7997\n",
      "Epoch 39 Loss: 7.7147\n",
      "Epoch 40 Loss: 7.7494\n",
      "Epoch 41 Loss: 7.1125\n",
      "Epoch 42 Loss: 7.3348\n",
      "Epoch 43 Loss: 7.3810\n",
      "Epoch 44 Loss: 7.2357\n",
      "Epoch 45 Loss: 7.2401\n",
      "Epoch 46 Loss: 7.0283\n",
      "Epoch 47 Loss: 6.8478\n",
      "Epoch 48 Loss: 6.8301\n",
      "Epoch 49 Loss: 6.9374\n",
      "Epoch 50 Loss: 6.8051\n",
      "Epoch 51 Loss: 6.7655\n",
      "Epoch 52 Loss: 6.3453\n",
      "Epoch 53 Loss: 6.5628\n",
      "Epoch 54 Loss: 6.5423\n",
      "Epoch 55 Loss: 6.6242\n",
      "Epoch 56 Loss: 6.4832\n",
      "Epoch 57 Loss: 6.2036\n",
      "Epoch 58 Loss: 6.5164\n",
      "Epoch 59 Loss: 6.1679\n",
      "Epoch 60 Loss: 6.2440\n",
      "Epoch 61 Loss: 6.1963\n",
      "Epoch 62 Loss: 6.1996\n",
      "Epoch 63 Loss: 5.8542\n",
      "Epoch 64 Loss: 6.2863\n",
      "Epoch 65 Loss: 5.8992\n",
      "Epoch 66 Loss: 5.7884\n",
      "Epoch 67 Loss: 5.7441\n",
      "Epoch 68 Loss: 5.8694\n",
      "Epoch 69 Loss: 5.9379\n",
      "Epoch 70 Loss: 5.5787\n",
      "Epoch 71 Loss: 5.7731\n",
      "Epoch 72 Loss: 5.6908\n",
      "Epoch 73 Loss: 5.6291\n",
      "Epoch 74 Loss: 5.9542\n",
      "Epoch 75 Loss: 5.7777\n",
      "Epoch 76 Loss: 5.6010\n",
      "Epoch 77 Loss: 5.2502\n",
      "Epoch 78 Loss: 4.6925\n",
      "Epoch 79 Loss: 4.7184\n",
      "Epoch 80 Loss: 4.6755\n",
      "Epoch 81 Loss: 4.3535\n",
      "Epoch 82 Loss: 4.5715\n",
      "Epoch 83 Loss: 4.2518\n",
      "Epoch 84 Loss: 4.2345\n",
      "Epoch 85 Loss: 4.4812\n",
      "Epoch 86 Loss: 4.3746\n",
      "Epoch 87 Loss: 4.0819\n",
      "Epoch 88 Loss: 4.3187\n",
      "Epoch 89 Loss: 4.0791\n",
      "Epoch 90 Loss: 4.3803\n",
      "Epoch 91 Loss: 4.1023\n",
      "Epoch 92 Loss: 4.0999\n",
      "Epoch 93 Loss: 3.9962\n",
      "Epoch 94 Loss: 4.1407\n",
      "Epoch 95 Loss: 3.9644\n",
      "Epoch 96 Loss: 3.8999\n",
      "Epoch 97 Loss: 4.0568\n",
      "Epoch 98 Loss: 3.9797\n",
      "Epoch 99 Loss: 3.9178\n",
      "Epoch 100 Loss: 3.8406\n",
      "Epoch 101 Loss: 3.7197\n",
      "Epoch 102 Loss: 3.9269\n",
      "Epoch 103 Loss: 3.6899\n",
      "Epoch 104 Loss: 3.8366\n",
      "Epoch 105 Loss: 3.8398\n",
      "Epoch 106 Loss: 3.9231\n",
      "Epoch 107 Loss: 3.7086\n",
      "Epoch 108 Loss: 3.7750\n",
      "Epoch 109 Loss: 3.8096\n",
      "Epoch 110 Loss: 3.7916\n",
      "Epoch 111 Loss: 3.3241\n",
      "Epoch 112 Loss: 3.4137\n",
      "Epoch 113 Loss: 3.2614\n",
      "Epoch 114 Loss: 3.1691\n",
      "Epoch 115 Loss: 3.1229\n",
      "Epoch 116 Loss: 3.1403\n",
      "Epoch 117 Loss: 3.0169\n",
      "Epoch 118 Loss: 3.1026\n",
      "Epoch 119 Loss: 3.0570\n",
      "Epoch 120 Loss: 2.9306\n",
      "Epoch 121 Loss: 2.9477\n",
      "Epoch 122 Loss: 2.9916\n",
      "Epoch 123 Loss: 2.8969\n",
      "Epoch 124 Loss: 2.8973\n",
      "Epoch 125 Loss: 2.8745\n",
      "Epoch 126 Loss: 2.9038\n",
      "Epoch 127 Loss: 2.8280\n",
      "Epoch 128 Loss: 2.8619\n",
      "Epoch 129 Loss: 2.7790\n",
      "Epoch 130 Loss: 2.9803\n",
      "Epoch 131 Loss: 2.7235\n",
      "Epoch 132 Loss: 2.9340\n",
      "Epoch 133 Loss: 2.7747\n",
      "Epoch 134 Loss: 2.9351\n",
      "Epoch 135 Loss: 2.6592\n",
      "Epoch 136 Loss: 2.7837\n",
      "Epoch 137 Loss: 2.6750\n",
      "Epoch 138 Loss: 2.7653\n",
      "Epoch 139 Loss: 2.7394\n",
      "Epoch 140 Loss: 2.6510\n",
      "Epoch 141 Loss: 2.5936\n",
      "Epoch 142 Loss: 2.6968\n",
      "Epoch 143 Loss: 2.6814\n",
      "Epoch 144 Loss: 2.8153\n",
      "Epoch 145 Loss: 2.6964\n",
      "Epoch 146 Loss: 2.6166\n",
      "Epoch 147 Loss: 2.6310\n",
      "Epoch 148 Loss: 2.6583\n",
      "Epoch 149 Loss: 2.5812\n",
      "Epoch 150 Loss: 2.5074\n",
      "Epoch 151 Loss: 2.5204\n",
      "Epoch 152 Loss: 2.3613\n",
      "Epoch 153 Loss: 2.3604\n",
      "Epoch 154 Loss: 2.3593\n",
      "Epoch 155 Loss: 2.3779\n",
      "Epoch 156 Loss: 2.2887\n",
      "Epoch 157 Loss: 2.2578\n",
      "Epoch 158 Loss: 2.2832\n",
      "Epoch 159 Loss: 2.3246\n",
      "Epoch 160 Loss: 2.2937\n",
      "Epoch 161 Loss: 2.0996\n",
      "Epoch 162 Loss: 2.3142\n",
      "Epoch 163 Loss: 2.2036\n",
      "Epoch 164 Loss: 2.3222\n",
      "Epoch 165 Loss: 2.2803\n",
      "Epoch 166 Loss: 2.2522\n",
      "Epoch 167 Loss: 2.2600\n",
      "Epoch 168 Loss: 2.2136\n",
      "Epoch 169 Loss: 2.0643\n",
      "Epoch 170 Loss: 2.1418\n",
      "Epoch 171 Loss: 2.1883\n",
      "Epoch 172 Loss: 2.1446\n",
      "Epoch 173 Loss: 2.1511\n",
      "Epoch 174 Loss: 1.9915\n",
      "Epoch 175 Loss: 2.1198\n",
      "Epoch 176 Loss: 2.0738\n",
      "Epoch 177 Loss: 2.0338\n",
      "Epoch 178 Loss: 2.0271\n",
      "Epoch 179 Loss: 2.0781\n",
      "Epoch 180 Loss: 2.1291\n",
      "Epoch 181 Loss: 2.0396\n",
      "Epoch 182 Loss: 2.0833\n",
      "Epoch 183 Loss: 2.0335\n",
      "Epoch 184 Loss: 2.0199\n",
      "Epoch 185 Loss: 2.0262\n",
      "Epoch 186 Loss: 2.0710\n",
      "Epoch 187 Loss: 2.0387\n",
      "Epoch 188 Loss: 2.0236\n",
      "Epoch 189 Loss: 2.0435\n",
      "Epoch 190 Loss: 1.9842\n",
      "Epoch 191 Loss: 1.9133\n",
      "Epoch 192 Loss: 1.9105\n",
      "Epoch 193 Loss: 1.9488\n",
      "Epoch 194 Loss: 1.9888\n",
      "Epoch 195 Loss: 1.8846\n",
      "Epoch 196 Loss: 1.9991\n",
      "Epoch 197 Loss: 1.9298\n",
      "Epoch 198 Loss: 2.0162\n",
      "Epoch 199 Loss: 1.8871\n",
      "Epoch 200 Loss: 1.8474\n",
      "Epoch 201 Loss: 1.8249\n",
      "Epoch 202 Loss: 1.9310\n",
      "Epoch 203 Loss: 1.8745\n",
      "Epoch 204 Loss: 1.9474\n",
      "Epoch 205 Loss: 1.9000\n",
      "Epoch 206 Loss: 1.9022\n",
      "Epoch 207 Loss: 1.9258\n",
      "Epoch 208 Loss: 1.7836\n",
      "Epoch 209 Loss: 1.8866\n",
      "Epoch 210 Loss: 1.8672\n",
      "Epoch 211 Loss: 1.8487\n",
      "Epoch 212 Loss: 1.9953\n",
      "Epoch 213 Loss: 1.9766\n",
      "Epoch 214 Loss: 1.9082\n",
      "Epoch 215 Loss: 1.8382\n",
      "Epoch 216 Loss: 1.8537\n",
      "Epoch 217 Loss: 1.9350\n",
      "Epoch 218 Loss: 2.0571\n",
      "Epoch 219 Loss: 1.8928\n",
      "Epoch 220 Loss: 1.8771\n",
      "Epoch 221 Loss: 1.9336\n",
      "Epoch 222 Loss: 1.9621\n",
      "Epoch 223 Loss: 1.8543\n",
      "Epoch 224 Loss: 1.9475\n",
      "Epoch 225 Loss: 1.8580\n",
      "Epoch 226 Loss: 1.8914\n",
      "Epoch 227 Loss: 1.8449\n",
      "Epoch 228 Loss: 1.8400\n",
      "Epoch 229 Loss: 1.8391\n",
      "Epoch 230 Loss: 1.9296\n",
      "Epoch 231 Loss: 1.9964\n",
      "Epoch 232 Loss: 1.8864\n",
      "Epoch 233 Loss: 1.8908\n",
      "Epoch 234 Loss: 2.0197\n",
      "Epoch 235 Loss: 1.8197\n",
      "Epoch 236 Loss: 2.0124\n",
      "Epoch 237 Loss: 1.7993\n",
      "Epoch 238 Loss: 1.9182\n",
      "Epoch 239 Loss: 1.9102\n",
      "Epoch 240 Loss: 1.7995\n",
      "Epoch 241 Loss: 1.8729\n",
      "Epoch 242 Loss: 1.9261\n",
      "Epoch 243 Loss: 1.8741\n",
      "Epoch 244 Loss: 1.8965\n",
      "Epoch 245 Loss: 2.0469\n",
      "Epoch 246 Loss: 1.8777\n",
      "Epoch 247 Loss: 1.9150\n",
      "Epoch 248 Loss: 1.9059\n",
      "Epoch 249 Loss: 1.9091\n",
      "Epoch 250 Loss: 1.8719\n",
      "Epoch 251 Loss: 1.8733\n",
      "Epoch 252 Loss: 1.9293\n",
      "Epoch 253 Loss: 1.8691\n",
      "Epoch 254 Loss: 1.7896\n",
      "Epoch 255 Loss: 1.8054\n",
      "Epoch 256 Loss: 2.0851\n",
      "Epoch 257 Loss: 1.8583\n",
      "Epoch 258 Loss: 1.8377\n",
      "Epoch 259 Loss: 1.8837\n",
      "Epoch 260 Loss: 1.9097\n",
      "Epoch 261 Loss: 1.9415\n",
      "Epoch 262 Loss: 1.8465\n",
      "Epoch 263 Loss: 1.8586\n",
      "Epoch 264 Loss: 1.8988\n",
      "Epoch 265 Loss: 1.8465\n",
      "Epoch 266 Loss: 1.9629\n",
      "Epoch 267 Loss: 1.9065\n",
      "Epoch 268 Loss: 1.9666\n",
      "Epoch 269 Loss: 1.8510\n",
      "Epoch 270 Loss: 1.9146\n",
      "Epoch 271 Loss: 1.9366\n",
      "Epoch 272 Loss: 1.7655\n",
      "Epoch 273 Loss: 1.8158\n",
      "Epoch 274 Loss: 1.8338\n",
      "Epoch 275 Loss: 1.8528\n",
      "Epoch 276 Loss: 1.9356\n",
      "Epoch 277 Loss: 1.9363\n",
      "Epoch 278 Loss: 1.8800\n",
      "Epoch 279 Loss: 1.8177\n",
      "Epoch 280 Loss: 1.8856\n",
      "Epoch 281 Loss: 1.8595\n",
      "Epoch 282 Loss: 1.9165\n",
      "Epoch 283 Loss: 1.7664\n",
      "Epoch 284 Loss: 1.8772\n",
      "Epoch 285 Loss: 1.9605\n",
      "Epoch 286 Loss: 1.9067\n",
      "Epoch 287 Loss: 1.9312\n",
      "Epoch 288 Loss: 1.8712\n",
      "Epoch 289 Loss: 2.0385\n",
      "Epoch 290 Loss: 1.8667\n",
      "Epoch 291 Loss: 1.8601\n",
      "Epoch 292 Loss: 1.9944\n",
      "Epoch 293 Loss: 1.8573\n",
      "Epoch 294 Loss: 1.8427\n",
      "Epoch 295 Loss: 1.8242\n",
      "Epoch 296 Loss: 1.9057\n",
      "Epoch 297 Loss: 1.8441\n",
      "Epoch 298 Loss: 1.8775\n",
      "Epoch 299 Loss: 1.9716\n",
      "Epoch 300 Loss: 1.9804\n",
      "Epoch 301 Loss: 1.8519\n",
      "Epoch 302 Loss: 1.9351\n",
      "Epoch 303 Loss: 1.9315\n",
      "Epoch 304 Loss: 1.8655\n",
      "Epoch 305 Loss: 1.9143\n",
      "Epoch 306 Loss: 1.8778\n",
      "Epoch 307 Loss: 1.9566\n",
      "Epoch 308 Loss: 1.8170\n",
      "Epoch 309 Loss: 1.8019\n",
      "Epoch 310 Loss: 1.9091\n",
      "Epoch 311 Loss: 1.8347\n",
      "Epoch 312 Loss: 1.8776\n",
      "Epoch 313 Loss: 1.8957\n",
      "Epoch 314 Loss: 1.9730\n",
      "Epoch 315 Loss: 1.9667\n",
      "Epoch 316 Loss: 1.8771\n",
      "Epoch 317 Loss: 1.9384\n",
      "Epoch 318 Loss: 1.8919\n",
      "Epoch 319 Loss: 1.8429\n",
      "Epoch 320 Loss: 1.8966\n",
      "Epoch 321 Loss: 1.9252\n",
      "Epoch 322 Loss: 1.8627\n",
      "Epoch 323 Loss: 1.9288\n",
      "Epoch 324 Loss: 1.8685\n",
      "Epoch 325 Loss: 1.9102\n",
      "Epoch 326 Loss: 1.8964\n",
      "Epoch 327 Loss: 1.9223\n",
      "Epoch 328 Loss: 1.8756\n",
      "Epoch 329 Loss: 1.9606\n",
      "Epoch 330 Loss: 1.9249\n",
      "Epoch 331 Loss: 1.8800\n",
      "Epoch 332 Loss: 1.8320\n",
      "Epoch 333 Loss: 1.9474\n",
      "Epoch 334 Loss: 1.8695\n",
      "Epoch 335 Loss: 1.9473\n",
      "Epoch 336 Loss: 1.9005\n",
      "Epoch 337 Loss: 1.8132\n",
      "Epoch 338 Loss: 1.9242\n",
      "Epoch 339 Loss: 1.9044\n",
      "Epoch 340 Loss: 1.8408\n",
      "Epoch 341 Loss: 1.8940\n",
      "Epoch 342 Loss: 1.8919\n",
      "Epoch 343 Loss: 1.8355\n",
      "Epoch 344 Loss: 1.9497\n",
      "Epoch 345 Loss: 1.9213\n",
      "Epoch 346 Loss: 1.9008\n",
      "Epoch 347 Loss: 1.8411\n",
      "Epoch 348 Loss: 1.8375\n",
      "Epoch 349 Loss: 1.8363\n",
      "Epoch 350 Loss: 1.8476\n",
      "Epoch 351 Loss: 1.9834\n",
      "Epoch 352 Loss: 1.9191\n",
      "Epoch 353 Loss: 2.0490\n",
      "Epoch 354 Loss: 1.7594\n",
      "Epoch 355 Loss: 1.9562\n",
      "Epoch 356 Loss: 1.8795\n",
      "Epoch 357 Loss: 1.9271\n",
      "Epoch 358 Loss: 1.9014\n",
      "Epoch 359 Loss: 1.8604\n",
      "Epoch 360 Loss: 1.9027\n",
      "Epoch 361 Loss: 1.9858\n",
      "Epoch 362 Loss: 1.9302\n",
      "Epoch 363 Loss: 1.8971\n",
      "Epoch 364 Loss: 1.8322\n",
      "Epoch 365 Loss: 1.9421\n",
      "Epoch 366 Loss: 1.9201\n",
      "Epoch 367 Loss: 1.9520\n",
      "Epoch 368 Loss: 1.8662\n",
      "Epoch 369 Loss: 1.8334\n",
      "Epoch 370 Loss: 1.8508\n",
      "Epoch 371 Loss: 1.8537\n",
      "Epoch 372 Loss: 1.9021\n",
      "Epoch 373 Loss: 1.9050\n",
      "Epoch 374 Loss: 1.9715\n",
      "Epoch 375 Loss: 1.7620\n",
      "Epoch 376 Loss: 1.8922\n",
      "Epoch 377 Loss: 1.9030\n",
      "Epoch 378 Loss: 1.8001\n",
      "Epoch 379 Loss: 1.7983\n",
      "Epoch 380 Loss: 1.9575\n",
      "Epoch 381 Loss: 1.9500\n",
      "Epoch 382 Loss: 1.9053\n",
      "Epoch 383 Loss: 1.9107\n",
      "Epoch 384 Loss: 1.8348\n",
      "Epoch 385 Loss: 1.9989\n",
      "Epoch 386 Loss: 1.8467\n",
      "Epoch 387 Loss: 2.0793\n",
      "Epoch 388 Loss: 1.9337\n",
      "Epoch 389 Loss: 1.8790\n",
      "Epoch 390 Loss: 1.9456\n",
      "Epoch 391 Loss: 1.9146\n",
      "Epoch 392 Loss: 1.8185\n",
      "Epoch 393 Loss: 1.9531\n",
      "Epoch 394 Loss: 1.8520\n",
      "Epoch 395 Loss: 1.7925\n",
      "Epoch 396 Loss: 1.8113\n",
      "Epoch 397 Loss: 1.8502\n",
      "Epoch 398 Loss: 1.9301\n",
      "Epoch 399 Loss: 1.8952\n",
      "Epoch 400 Loss: 1.8783\n",
      "Epoch 401 Loss: 1.8160\n",
      "Epoch 402 Loss: 1.9688\n",
      "Epoch 403 Loss: 1.9026\n",
      "Epoch 404 Loss: 1.8422\n",
      "Epoch 405 Loss: 1.8158\n",
      "Epoch 406 Loss: 1.9594\n",
      "Epoch 407 Loss: 1.9162\n",
      "Epoch 408 Loss: 1.8922\n",
      "Epoch 409 Loss: 1.7957\n",
      "Epoch 410 Loss: 1.9324\n",
      "Epoch 411 Loss: 1.8880\n",
      "Epoch 412 Loss: 1.8446\n",
      "Epoch 413 Loss: 1.8149\n",
      "Epoch 414 Loss: 1.9703\n",
      "Epoch 415 Loss: 1.8679\n",
      "Epoch 416 Loss: 1.9373\n",
      "Epoch 417 Loss: 1.9215\n",
      "Epoch 418 Loss: 1.8336\n",
      "Epoch 419 Loss: 1.8387\n",
      "Epoch 420 Loss: 1.9740\n",
      "Epoch 421 Loss: 1.9661\n",
      "Epoch 422 Loss: 1.9341\n",
      "Epoch 423 Loss: 1.8773\n",
      "Epoch 424 Loss: 1.7846\n",
      "Epoch 425 Loss: 1.8343\n",
      "Epoch 426 Loss: 1.8754\n",
      "Epoch 427 Loss: 1.8692\n",
      "Epoch 428 Loss: 1.8879\n",
      "Epoch 429 Loss: 1.9010\n",
      "Epoch 430 Loss: 1.9151\n",
      "Epoch 431 Loss: 1.9790\n",
      "Epoch 432 Loss: 1.9692\n",
      "Epoch 433 Loss: 1.8865\n",
      "Epoch 434 Loss: 1.8875\n",
      "Epoch 435 Loss: 1.9190\n",
      "Epoch 436 Loss: 2.1089\n",
      "Epoch 437 Loss: 1.8523\n",
      "Epoch 438 Loss: 1.8527\n",
      "Epoch 439 Loss: 2.0057\n",
      "Epoch 440 Loss: 1.9957\n",
      "Epoch 441 Loss: 1.8748\n",
      "Epoch 442 Loss: 1.9947\n",
      "Epoch 443 Loss: 1.8454\n",
      "Epoch 444 Loss: 1.9768\n",
      "Epoch 445 Loss: 1.8979\n",
      "Epoch 446 Loss: 1.8866\n",
      "Epoch 447 Loss: 1.8574\n",
      "Epoch 448 Loss: 1.9252\n",
      "Epoch 449 Loss: 1.9044\n",
      "Epoch 450 Loss: 1.8235\n",
      "Epoch 451 Loss: 1.9239\n",
      "Epoch 452 Loss: 1.8002\n",
      "Epoch 453 Loss: 1.9166\n",
      "Epoch 454 Loss: 1.9967\n",
      "Epoch 455 Loss: 1.8947\n",
      "Epoch 456 Loss: 1.8966\n",
      "Epoch 457 Loss: 1.8827\n",
      "Epoch 458 Loss: 1.9120\n",
      "Epoch 459 Loss: 1.9203\n",
      "Epoch 460 Loss: 2.0324\n",
      "Epoch 461 Loss: 1.8788\n",
      "Epoch 462 Loss: 1.9520\n",
      "Epoch 463 Loss: 1.8377\n",
      "Epoch 464 Loss: 1.9513\n",
      "Epoch 465 Loss: 1.9582\n",
      "Epoch 466 Loss: 1.8529\n",
      "Epoch 467 Loss: 1.9333\n",
      "Epoch 468 Loss: 1.9040\n",
      "Epoch 469 Loss: 1.9638\n",
      "Epoch 470 Loss: 1.8777\n",
      "Epoch 471 Loss: 1.9152\n",
      "Epoch 472 Loss: 1.8626\n",
      "Epoch 473 Loss: 1.8892\n",
      "Epoch 474 Loss: 1.8474\n",
      "Epoch 475 Loss: 1.9289\n",
      "Epoch 476 Loss: 1.9063\n",
      "Epoch 477 Loss: 1.8316\n",
      "Epoch 478 Loss: 1.9948\n",
      "Epoch 479 Loss: 1.9030\n",
      "Epoch 480 Loss: 1.8433\n",
      "Epoch 481 Loss: 1.8591\n",
      "Epoch 482 Loss: 1.9609\n",
      "Epoch 483 Loss: 1.9713\n",
      "Epoch 484 Loss: 1.8108\n",
      "Epoch 485 Loss: 1.9637\n",
      "Epoch 486 Loss: 1.7921\n",
      "Epoch 487 Loss: 1.8444\n",
      "Epoch 488 Loss: 1.9412\n",
      "Epoch 489 Loss: 1.8482\n",
      "Epoch 490 Loss: 1.8843\n",
      "Epoch 491 Loss: 1.9657\n",
      "Epoch 492 Loss: 1.9322\n",
      "Epoch 493 Loss: 1.8439\n",
      "Epoch 494 Loss: 1.7864\n",
      "Epoch 495 Loss: 1.8706\n",
      "Epoch 496 Loss: 1.8726\n",
      "Epoch 497 Loss: 1.8455\n",
      "Epoch 498 Loss: 1.8344\n",
      "Epoch 499 Loss: 1.9527\n",
      "Epoch 500 Loss: 1.9146\n",
      "Using 12 cores for parallel processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7c473b999d49c5b5e12cce71d67c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Recommendations:   0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneural\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/id_lyrics_bert_mmsr.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m----> 3\u001b[0m recs_neural_net \u001b[38;5;241m=\u001b[39m all_neural_net_recs(infos, features, topK\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, use_cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./predictions/recs_neural_net_10.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, recs_neural_net, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\pythonProject\\MSR\\final\\neural.py:142\u001b[0m, in \u001b[0;36mall_neural_net_recs\u001b[1;34m(infos, features, topK, use_cuda, epochs)\u001b[0m\n\u001b[0;32m    140\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, os\u001b[38;5;241m.\u001b[39mcpu_count() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_jobs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cores for parallel processing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 142\u001b[0m results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(\n\u001b[0;32m    143\u001b[0m     delayed(generate_recommendations_for_song)(i, model, features, infos, topK, use_cuda)\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(features)), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating Recommendations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m )\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Create the recommendation matrix\u001b[39;00m\n\u001b[0;32m    148\u001b[0m recs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(features), \u001b[38;5;28mlen\u001b[39m(features)))\n",
      "File \u001b[1;32mD:\\conda_envs\\condaenv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mD:\\conda_envs\\condaenv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\conda_envs\\condaenv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from neural import *\n",
    "features = pd.read_csv(\"dataset/id_lyrics_bert_mmsr.tsv\", sep=\"\\t\").drop(columns=[\"id\"]).values\n",
    "recs_neural_net = all_neural_net_recs(infos, features, topK=10, use_cuda=True, epochs=500)\n",
    "np.savetxt(\"./predictions/recs_neural_net_10.csv\", recs_neural_net, delimiter=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
