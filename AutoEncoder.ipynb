{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51de3d-be82-4428-8528-894b8141b50e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 271\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     final_labels_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m feature_train, feature_test, label_train, label_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused_df_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_labels_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[0;32m    273\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m Music4AllOnionDataset(feature_train, label_train)\n\u001b[0;32m    276\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Justin\\Documents\\JKU\\2024WS\\multimedia-search-and-retrieval\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Justin\\Documents\\JKU\\2024WS\\multimedia-search-and-retrieval\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2810\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2806\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2808\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[1;32m-> 2810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2814\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Justin\\Documents\\JKU\\2024WS\\multimedia-search-and-retrieval\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2812\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2806\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2808\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m   2810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2811\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2812\u001b[0m         (\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m, _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2813\u001b[0m     )\n\u001b[0;32m   2814\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Justin\\Documents\\JKU\\2024WS\\multimedia-search-and-retrieval\\.venv\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:269\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_list_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Justin\\Documents\\JKU\\2024WS\\multimedia-search-and-retrieval\\.venv\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:60\u001b[0m, in \u001b[0;36m_list_indexing\u001b[1;34m(X, key, key_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(compress(X, key))\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# key is a integer array-like of key\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m key]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def cosine_similarity(vec_a, vec_b, eps=1e-9):\n",
    "    dot = np.dot(vec_a, vec_b)\n",
    "    norm_a = np.linalg.norm(vec_a)\n",
    "    norm_b = np.linalg.norm(vec_b)\n",
    "    return dot / ((norm_a * norm_b) + eps)\n",
    "\n",
    "\n",
    "def load_and_merge_numeric_features(file_list, merge_on='id'):\n",
    "    base_df = pd.read_csv(file_list[0], sep='\\t')\n",
    "    for path in file_list[1:]:\n",
    "        df_next = pd.read_csv(path, sep='\\t')\n",
    "        base_df = pd.merge(base_df, df_next, on=merge_on, how='inner')\n",
    "    base_df.set_index(merge_on, inplace=True)\n",
    "    return base_df\n",
    "\n",
    "def normalize_features(df):\n",
    "    scaler = StandardScaler()\n",
    "    return pd.DataFrame(scaler.fit_transform(df), index=df.index, columns=df.columns)\n",
    "\n",
    "class Music4AllOnionDataset(Dataset):\n",
    "    def __init__(self, feature_df, label_df=None, transform=None):\n",
    "        self.transform = transform\n",
    "        feature_df = feature_df.sort_index()\n",
    "        self.feature_df = feature_df\n",
    "\n",
    "        if label_df is not None:\n",
    "            label_df = label_df.sort_index()\n",
    "            common_idx = feature_df.index.intersection(label_df.index)\n",
    "            self.feature_df = feature_df.loc[common_idx]\n",
    "            self.label_df = label_df.loc[common_idx]\n",
    "            self.has_labels = True\n",
    "        else:\n",
    "            self.label_df = None\n",
    "            self.has_labels = False\n",
    "\n",
    "        self.feature_data = self.feature_df.values.astype(np.float32)\n",
    "        if self.transform:\n",
    "            self.feature_data = self.transform(self.feature_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.feature_data[idx]\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "\n",
    "        if self.has_labels:\n",
    "            y_val = self.label_df.iloc[idx].values\n",
    "            y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "            return x, y_val\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=128):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, reconstruct=False):\n",
    "        z = self.encoder(x)\n",
    "        if reconstruct:\n",
    "            return self.decoder(z)\n",
    "        return z\n",
    "\n",
    "class FineTuneClassifier(nn.Module):\n",
    "    def __init__(self, autoenc, latent_dim, num_classes):\n",
    "        super(FineTuneClassifier, self).__init__()\n",
    "        self.autoenc = autoenc\n",
    "        for param in self.autoenc.encoder.parameters():\n",
    "            param.requires_grad = False  \n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            z = self.autoenc.encoder(x)  \n",
    "        logits = self.classifier(z)\n",
    "        return logits\n",
    "\n",
    "def train_autoenc(model, dataloader, num_epochs=50, lr=1e-3, patience=5, device='cuda'):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for x, _ in dataloader:\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_recon = model(x, reconstruct=True)\n",
    "            loss = criterion(x_recon, x)  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(dataloader)\n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "\n",
    "def train_classifier(\n",
    "    model, dataloader, num_epochs=20, lr=1e-3, patience=5, device='cuda'\n",
    "):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y.squeeze().long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(dataloader)\n",
    "        print(f\"[Classifier Epoch {epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "def compute_all_embeddings(dataset, model, device='cuda'):\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        item = dataset[i]\n",
    "        x = item[0] if isinstance(item, tuple) else item\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            z = model(x)\n",
    "        z_np = z.cpu().numpy().flatten()\n",
    "        all_embeddings.append(z_np)\n",
    "\n",
    "    embeddings = np.vstack(all_embeddings)\n",
    "    return embeddings\n",
    "\n",
    "def build_recommendation_matrix(embeddings, topK=10):\n",
    "    N = len(embeddings)\n",
    "    rec_matrix = np.zeros((N, N), dtype=np.float32)\n",
    "\n",
    "    for i in tqdm(range(N), desc=\"Building Recs\"):\n",
    "        vec_i = embeddings[i]\n",
    "        sims = [cosine_similarity(vec_i, embeddings[j]) for j in range(N)]\n",
    "        sims = np.array(sims)\n",
    "        sims[i] = -1e9\n",
    "        topk_idx = sims.argsort()[::-1][:topK]\n",
    "        topk_vals = sims[topk_idx]\n",
    "        rec_matrix[i, topk_idx] = topk_vals\n",
    "\n",
    "    return rec_matrix\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "numeric_files = [\n",
    "        \"./dataset/id_blf_correlation_mmsr.tsv\",\n",
    "        \"./dataset/id_blf_deltaspectral_mmsr.tsv\",\n",
    "        \"./dataset/id_blf_logfluc_mmsr.tsv\",\n",
    "        \"./dataset/id_blf_spectral_mmsr.tsv\",\n",
    "        \"./dataset/id_blf_spectralcontrast_mmsr.tsv\",\n",
    "        \"./dataset/id_blf_vardeltaspectral_mmsr.tsv\",\n",
    "        \"./dataset/id_incp_mmsr.tsv\",\n",
    "        \"./dataset/id_ivec256_mmsr.tsv\",\n",
    "        \"./dataset/id_ivec512_mmsr.tsv\",\n",
    "        \"./dataset/id_ivec1024_mmsr.tsv\",\n",
    "        \"./dataset/id_lyrics_tf-idf_mmsr.tsv\",\n",
    "        \"./dataset/id_lyrics_word2vec_mmsr.tsv\",\n",
    "        \"./dataset/id_lyrics_bert_mmsr.tsv\",\n",
    "        \"./dataset/id_mfcc_bow_mmsr.tsv\",\n",
    "        \"./dataset/id_mfcc_stats_mmsr.tsv\",\n",
    "        \"./dataset/id_musicnn_mmsr.tsv\",\n",
    "        \"./dataset/id_resnet_mmsr.tsv\",\n",
    "        \"./dataset/id_vgg19_mmsr.tsv\",\n",
    "        \"./dataset/id_total_listens.tsv\"\n",
    "]\n",
    "\n",
    "fused_df = load_and_merge_numeric_features(numeric_files, merge_on='id')\n",
    "fused_df_normalized = normalize_features(fused_df)\n",
    "\n",
    "labels_path = \"id_genres_mmsr.tsv\"\n",
    "if os.path.exists(labels_path):\n",
    "        labels_df = pd.read_csv(labels_path, sep='\\t').set_index('id')\n",
    "        unique_genres = labels_df['genre'].unique()\n",
    "        genre_to_idx = {g: i for i, g in enumerate(unique_genres)}\n",
    "        labels_df['genre_id'] = labels_df['genre'].map(genre_to_idx)\n",
    "        final_labels_df = labels_df[['genre_id']]\n",
    "else:\n",
    "    final_labels_df = None\n",
    "\n",
    "feature_train, feature_test, label_train, label_test = train_test_split(\n",
    "        fused_df_normalized, final_labels_df, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Music4AllOnionDataset(feature_train, label_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "test_dataset = Music4AllOnionDataset(feature_test, label_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "input_dim = fused_df_normalized.shape[1]\n",
    "latent_dim = 128\n",
    "\n",
    "autoenc_model = AutoEncoder(input_dim, latent_dim=latent_dim)\n",
    "train_autoenc(autoenc_model, train_loader, num_epochs=250, lr=1e-3, patience=100, device=device)\n",
    "\n",
    "if final_labels_df is not None:\n",
    "    num_classes = len(np.unique(final_labels_df['genre_id']))\n",
    "    classifier_model = FineTuneClassifier(autoenc_model, latent_dim, num_classes)\n",
    "    train_classifier(classifier_model, train_loader, num_epochs=250, patience=100, lr=1e-3, device=device)\n",
    "\n",
    "full_dataset = Music4AllOnionDataset(fused_df_normalized)\n",
    "embeddings = compute_all_embeddings(full_dataset, autoenc_model, device=device)\n",
    "rec_matrix = build_recommendation_matrix(embeddings, topK=10)\n",
    "np.savetxt(\"./predictions/rets_auto_enc_10_matrix\", rec_matrix, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffbad02-a9c7-4572-8556-bab283e4b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_recommendations(embeddings, ids, infos, topK=10):\n",
    "    recommendations = []\n",
    "    N = len(embeddings)\n",
    "\n",
    "    for i in tqdm(range(N), desc=\"Building Recommendations\"):\n",
    "        vec_i = embeddings[i]\n",
    "        sims = [\n",
    "            {\"source_id\": ids[i], \"target_id\": ids[j], \"similarity\": cosine_similarity(vec_i, embeddings[j])}\n",
    "            for j in range(N) if i != j\n",
    "        ]\n",
    "        top_k_recs = sorted(sims, key=lambda x: x[\"similarity\"], reverse=True)[:topK]\n",
    "        recommendations.extend(top_k_recs)\n",
    "\n",
    "    return pd.DataFrame(recommendations)\n",
    "\n",
    "full_dataset = Music4AllOnionDataset(fused_df_normalized)\n",
    "embeddings = compute_all_embeddings(full_dataset, autoenc_model, device=device)\n",
    "ids = fused_df_normalized.index.tolist()\n",
    "recommendations = build_recommendations(embeddings, ids, fused_df_normalized, topK=100)\n",
    "recommendations.to_csv(\"./predictions/ui/rets_auto_enc_10\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
